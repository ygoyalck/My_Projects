{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pin Code Recognition\n",
    "The first digit indicates one of the regions. The second digit indicates the sub region or one of the postal circles (States). The third digit indicates a sorting / revenue district. The last 3 digits refer to the delivery Post Office."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Meaning Of PIN code Digits**\n",
    "![](pinmeaning.PNG)\n",
    "![](pinmeaning2.PNG)\n",
    "If the PINCODE is 500072, then 5 indicates Southern region & 50 indicates Telangana. 500 indicates the district of Rangareddy/Hyderabad and the last 3 digits (072) indicate the KPHB colony post office in this area. That is how the postal department sorts the incoming mails and routes them to the correct post office."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TensorFlow\n",
    "TensorFlow is an open-source software library for dataflow programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks. It is used for both research and production at Google, often replacing its closed-source predecessor, DistBelief.\n",
    "\n",
    "TensorFlow computations are expressed as stateful dataflow graphs. The name TensorFlow derives from the operations that such neural networks perform on multidimensional data arrays. These arrays are referred to as \"tensors\". In June 2016, Dean stated that 1,500 repositories on GitHub mentioned TensorFlow, of which only 5 were from Google.\n",
    "\n",
    "TensorFlow is cross-platform. It runs on nearly everything: GPUs and CPUs—including mobile and embedded platforms—and even tensor processing units (TPUs), which are specialized hardware to do tensor math on.\n",
    "\n",
    "The TensorFlow distributed execution engine abstracts away the many supported devices and provides a high performance-core implemented in C++ for the TensorFlow platform. On top of that sit the Python and C++ frontends (with more to come). The Layers API provides a simpler interface for commonly used layers in deep learning models. On top of that sit higher-level APIs, including Keras (more on the Keras.io site) and the Estimator API, which makes training and evaluating distributed models easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess=tf.Session()\n",
    "a=tf.constant(6)\n",
    "b=tf.constant(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 15]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constants can be 2D matrices, strings etc.\n",
    "a1 = tf.constant([[3,3]])\n",
    "a2 = tf.constant([[3,2],[3,3]])\n",
    "res = tf.matmul(a1, a2)\n",
    "sess.run(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tf.constant(8)\n",
    "a=tf.constant(28) # is perfectly valid as a new tensor object is created here \n",
    "\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1=tf.Variable(100)\n",
    "sess.run(tf.global_variables_initializer()) # initializing global variable var1 now\n",
    "sess.run(var1)  #var1 containes old value b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "temp=var1.assign(122) #thats why called varibles\n",
    "sess.run(temp)  \n",
    "print(sess.run(var1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Placeholders**\n",
    "\n",
    "Placeholders are used when values are supposed to be provided later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =tf.placeholder(tf.int32) \n",
    "y =tf.placeholder(tf.int32)\n",
    "v=3*x\n",
    "sess=tf.Session()\n",
    "sess.run(v,feed_dict={x:20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 24],\n",
       "       [48, 60]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =tf.placeholder(tf.int32,shape=(2,2))\n",
    "y = x * tf.constant(12)\n",
    "sess.run(y, feed_dict={x:[[1,2], [4,5]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognizier Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-6d0342535e87>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import  input_data\n",
    "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image1=mnist.train.images[4119]\n",
    "image1=np.array(image1,float)\n",
    "image1=image1.reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input=784\n",
    "n_hl1=256\n",
    "n_hl2=256\n",
    "n_output=10\n",
    "\n",
    "weights={\n",
    "    'h1':tf.Variable(tf.random_normal(shape=(n_input,n_hl1))), \n",
    "    'h2':tf.Variable(tf.random_normal(shape=(n_hl1,n_hl2))),    \n",
    "    'out':tf.Variable(tf.random_normal(shape=(n_hl2,n_output))) \n",
    "}\n",
    "biases={\n",
    "    'h1':tf.Variable(tf.random_normal(shape=(n_hl1,))),         \n",
    "    'h2':tf.Variable(tf.random_normal(shape=(n_hl2,))),         \n",
    "    'out':tf.Variable(tf.random_normal(shape=(n_output,)))      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fwd_prop(x,weights,biases):\n",
    "    layer1=tf.add(tf.matmul(x,weights['h1']),biases['h1'])\n",
    "    layer1=tf.nn.relu(layer1)   \n",
    "    \n",
    "    layer2=tf.add(tf.matmul(layer1,weights['h2']),biases['h2'])\n",
    "    layer2=tf.nn.relu(layer2)\n",
    "    \n",
    "    output=tf.add(tf.matmul(layer2,weights['out']),biases['out'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=tf.placeholder('float',[None,n_input])    \n",
    "y=tf.placeholder(tf.int32,[None,n_output])\n",
    "pred=fwd_prop(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred,labels=y)) #logits is because of multiple classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize=optimizer.minimize(cost)\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25470.2491958\n",
      "4823.79512126\n",
      "2608.86271015\n",
      "1889.75779545\n",
      "1474.62110285\n",
      "1168.70110431\n",
      "1219.64641168\n",
      "1014.81162643\n",
      "922.471451166\n",
      "757.44732996\n",
      "798.348160325\n",
      "624.55007864\n",
      "642.040375067\n",
      "594.762212956\n",
      "399.140004131\n",
      "480.448584297\n",
      "370.694821787\n",
      "402.721022615\n",
      "313.184212845\n",
      "309.782306282\n",
      "254.669104677\n",
      "259.031151767\n",
      "183.59731102\n",
      "175.117321657\n",
      "193.215624113\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "for i in range(25):\n",
    "    num_batches=mnist.train.num_examples//batch_size\n",
    "    total_cost=0\n",
    "    for j in range(num_batches):\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        c,_=sess.run([cost,optimize],feed_dict={x:batch_x,y:batch_y})\n",
    "        total_cost+=c\n",
    "    print(total_cost)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9591"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=tf.argmax(pred,1)\n",
    "true_labels=tf.argmax(y,1)\n",
    "correct_preds=tf.equal(predictions,true_labels)\n",
    "correct_ones=sess.run(correct_preds,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "correct_ones.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Networks\n",
    "\n",
    "A covnets is a sequence of layers, and every layer transforms one volume to another through differentiable function.\n",
    "Types of layers:\n",
    "Let’s take an example by running a covnets on of image of dimension 32 x 32 x 3.\n",
    "\n",
    "**Input Layer**: This layer holds the raw input of image with width 32, height 32 and depth 3.\n",
    "\n",
    "**Convolution Layer**: This layer computes the output volume by computing dot product between all filters and image patch. Suppose we use total 12 filters for this layer we’ll get output volume of dimension 32 x 32 x 12.\n",
    "\n",
    "**Activation Function Layer**: This layer will apply element wise activation function to the output of convolution layer. Some common activation functions are RELU: max(0, x), Sigmoid: 1/(1+e^-x), Tanh, Leaky RELU, etc. The volume remains unchanged hence output volume will have dimension 32 x 32 x 12.\n",
    "\n",
    "**Pool Layer**: This layer is periodically inserted in the covnets and its main function is to reduce the size of volume which makes the computation fast reduces memory and also prevents from overfitting. Two common types of pooling layers are max pooling and average pooling. If we use a max pool with 2 x 2 filters and stride 2, the resultant volume will be of dimension 16x16x12.\n",
    "![](maxpool.png)\n",
    "Dropout is one of the most interesting ways to regularize your neural network. \n",
    "Dropout is a regularization technique where, while you're updating a layer of your neural net, you randomly don't update, or \"dropout,\" half of the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Architechture**\n",
    "\n",
    "![](CNNarchi.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_width = 28\n",
    "input_height = 28\n",
    "input_channels = 1\n",
    "input_pixels = 784\n",
    "\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "conv1_k = 5\n",
    "conv2_k = 5\n",
    "max_pool1_k = 2\n",
    "max_pool2_k = 2\n",
    "\n",
    "n_hidden = 1024\n",
    "n_out = 10\n",
    "\n",
    "input_size_to_hidden = (input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k)) *n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"wc1\" : tf.Variable(tf.random_normal([conv1_k, conv1_k, input_channels, n_conv1])),\n",
    "    \"wc2\" : tf.Variable(tf.random_normal([conv2_k, conv2_k, n_conv1, n_conv2])),\n",
    "    \"wh1\" : tf.Variable(tf.random_normal([input_size_to_hidden, n_hidden])),\n",
    "    \"wo\" : tf.Variable(tf.random_normal([n_hidden, n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random_normal([n_conv1])),\n",
    "    \"bc2\" : tf.Variable(tf.random_normal([n_conv2])),\n",
    "    \"bh1\" : tf.Variable(tf.random_normal([n_hidden])),\n",
    "    \"bo\" : tf.Variable(tf.random_normal([n_out])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(x, weights, bias, strides = 1):\n",
    "    out = tf.nn.conv2d(x, weights, padding=\"SAME\", strides = [1, strides, strides, 1])\n",
    "    out = tf.nn.bias_add(out, bias)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "def maxpooling(x, k = 2):\n",
    "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1, k, k, 1], strides = [1, k, k, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn(x, weights, biases, keep_prob):\n",
    "    x = tf.reshape(x, shape = [-1 ,input_height, input_width, input_channels])\n",
    "    conv1 = conv(x, weights['wc1'], biases['bc1'], stride_conv1)\n",
    "    conv1_pool = maxpooling(conv1, max_pool1_k)\n",
    "    \n",
    "    conv2 = conv(conv1_pool, weights['wc2'], biases['bc2'], stride_conv2)\n",
    "    conv2_pool = maxpooling(conv2, max_pool2_k)\n",
    "    \n",
    "    hidden_input = tf.reshape(conv2_pool, shape = [-1, input_size_to_hidden])\n",
    "    hidden_output_before_activation = tf.add(tf.matmul(hidden_input, weights['wh1']), biases['bh1'])\n",
    "    hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
    "    hidden_output = tf.nn.dropout(hidden_output_before_dropout, keep_prob) \n",
    "   \n",
    "    output = tf.add(tf.matmul(hidden_output, weights['wo']), biases['bo'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, input_pixels])\n",
    "y = tf.placeholder(tf.int32, [None, n_out])\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "pred = cnn(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(mnist.train.num_examples/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost,optimize], feed_dict={x:batch_x , y:batch_y, keep_prob:0.8})\n",
    "        total_cost += c\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = tf.argmax(pred, 1)\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "predictions,correct_preds  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels, keep_prob:1.0})\n",
    "correct_preds.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
