{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Word2Vec Model\n",
    "- Word2Vec Google's Pretrained Model\n",
    "- Contains vector representations of 50 billion words\n",
    "\n",
    "- Words which are similar in context have similar vectors\n",
    "- Distance/Similarity between two words can be measured using Cosine Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "- Text Similarity\n",
    "- Odd one Out\n",
    "- Fill in the Blanks\n",
    "- Word Analogies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "- Word embeddings are numerical representation of words, in the form of vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Word2Vec](word2vec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding is one of the most popular representation of document vocabulary. It is capable of capturing context of a word in a document, relation with other words, etc.\n",
    "![](WordEmbeddings.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec Algorithms**\n",
    "\n",
    "**CBOW Model** and **SkipGram Model**\n",
    "\n",
    "CBOW and Skip gram are word2vec model. Both use neural network architecture where the skip-gram inverts contexts and targets, and tries to predict each context word from its target word whereas CBOW is the reverse of it, it has context and the targeted word needs to be identified. The CBOW model is as follows.\n",
    "![](cbow.PNG)\n",
    "\n",
    "              The SkipGram Model is as follows\n",
    "![](skip.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, CBOW is learning to predict the word by the context. Or maximize the probability of the target word by looking at the context. And this happens to be a problem for rare words. For example, given the context \"yesterday was a really [...] day\" CBOW model will tell you that most probably the word is beautiful or nice. Words like delightful will get much less attention of the model, because it is designed to predict the most probable word. This word will be smoothed over a lot of examples with more frequent words.\n",
    "\n",
    "On the other hand, the skip-gram model is designed to predict the context. Given the word delightful it must understand it and tell us that there is a huge probability that the context is \"yesterday was really [...] day\", or some other relevant context. With skip-gram the word delightful will not try to compete with the word beautiful but instead, delightful+context pairs will be treated as new observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CBOW and SkipGram Architechture**\n",
    "\n",
    "Given a set of sentences (also called corpus) the model loops on the words of each sentence and either tries to use the current word of to predict its neighbors (its context), in which case the method is called “Skip-Gram”, or it uses each of these contexts to predict the current word, in which case the method is called “Continuous Bag Of Words” (CBOW). The limit on the number of words in each context is determined by a parameter called “window size”.\n",
    "The skip-gram neural network model is actually surprisingly simple in its most basic form. \n",
    "\n",
    "**Working**\n",
    "\n",
    "Train a simple neural network with a single hidden layer to perform a certain task, but then we’re not actually going to use that neural network for the task we trained it on! Instead, the goal is actually just to learn the weights of the hidden layer–we’ll see that these weights actually from the Embeddings' matrix that we’re trying to learn.\n",
    "We’re going to represent an input word like “ants” as a one-hot vector. This vector will have n components (one for every word in our vocabulary) and we’ll place a “1” in the position corresponding to the word “ants”, and 0s in all of the other positions.\n",
    "There is no activation function on the hidden layer neurons, but the output neurons use softmax.\n",
    "\n",
    "                                                   CBOW-Architechture\n",
    "![](arch1.PNG)\n",
    "For our example, we’re going to say that we’re learning word vectors with 300 features. So the hidden layer is going to be represented by a weight matrix with 10,000 rows (one for every word in our vocabulary) and 300 columns (one for every hidden neuron).\n",
    "\n",
    "                                                  SkipGram-Architechture\n",
    "![](arch2.PNG)\n",
    "So the end goal of all of this is really just to learn this hidden layer weight matrix — the output layer we’ll just toss when we’re done! The 1 x 300 word vector for “ants” then gets fed to the output layer. The output layer is a softmax regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Embeddings Matrix from Neural Network**\n",
    "![](gwe1.PNG)\n",
    "![](gwe2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cosine Similarity**\n",
    "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them.Given two vectors of attributes, A and B, the cosine similarity, cos(θ), is represented using a dot product.\n",
    "![](cosine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Analogies**\n",
    "At its most basic, an analogy is a comparison of two things to show their similarities. Sometimes the things being compared are quite similar, but other times they could be very different. \n",
    "![](eqn.PNG)\n",
    "Nevertheless, an analogy explains one thing in terms of another to highlight the ways in which they are alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Our Own Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec model can learn embeddings from any text corpus!\n",
    "- Continuous Bag of Words Model\n",
    "- Skip Gram Model\n",
    "\n",
    "`Algorithm looks at window of target word(Y) to provide context word(X), the model is trained on (X,Y) pairs in a supervised manner.` The algorithm was developed by Tomas Mikolov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each sentence must be tokenized, into a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopw  = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(file): \n",
    "    f = open(file,'r')\n",
    "    text = f.read()\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    data = []\n",
    "    for sent in sentences:\n",
    "        words =  nltk.word_tokenize(sent)\n",
    "        words = [w.lower() for w in words if len(w)>2 and w not in stopw]\n",
    "        data.append(words)\n",
    "        \n",
    "    return data\n",
    "\n",
    "text = readFile('bollywood.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018'], ['the', 'deepika', 'ranveer', 'celebrations', 'hooked', 'phones', 'waiting', 'whatâ€™s', 'come', 'also', 'gave', 'enough', 'reason', 'believe', 'stylish', 'two', 'couple'], ['from', 'airport', 'looks', 'reception', 'parties', 'everything', 'hereâ€™s', 'entire', 'timeline', 'deepika', 'ranveer', 'wedding', 'style', 'file'], ['not', 'ambanis', 'deepika', 'ranveer', 'priyanka', 'nick'], ['man', 'proves', 'wedding', 'the', 'year', 'this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['priyanka', 'also', 'shared', 'video', 'featuring', 'nick', 'jonaswas', 'also', 'celebrating', 'the', 'family', 'first', 'celebrated', 'christmas', 'london', 'pictures', 'priyanka', 'chopra', 'nick', 'jonas', 'new', 'year', 'celebrations', 'outstanding'], ['priyanka', 'chopra', 'nick', 'shared', 'glimpses', 'celebration', 'verbier', 'switzerland'], ['priyanka', 'chopra', 'married', 'nick', 'jonas', 'december', 'three', 'wedding', 'receptions', 'one', 'new', 'delhi', 'two', 'mumbai'], ['this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['kapil', 'sharma', 'ginni', 'chatrath', 'jaggo', 'night', 'december', 'made', 'even', 'special', 'industry', 'friends'], ['kapil', 'sharma', 'ginni', 'chatrath', 'friends', 'long', 'time'], ['there', 'virat', 'side', 'actress', 'wife', 'anushka', 'sharma', 'pleasure', 'audience'], ['while', 'couple', 'rang', 'new', 'year', 'style', 'morning', 'saw', 'virat', 'dress', 'squad', 'attire', 'anushka', 'pink', 'salwar', 'suit'], ['isha', 'ambani', 'married', 'anand', 'piramal', 'year']]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(text,size=300,window=10,min_count=1)\n",
    "#discard words of frequency less than min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=118, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dress', 'morning', 'isha', 'celebrating', 'suit', 'one', 'celebrations', 'chatrath', 'singh', 'entire', 'sharma', 'believe', 'three', 'nothing', 'jonaswas', 'hooked', 'file', 'even', 'reception', 'made', 'pictures', 'anand', 'happened', 'mumbai', 'stylish', 'delhi', 'hereâ€™s', 'timeline', 'ambani', 'grand', 'year', 'bollywood', 'media', 'celebration', 'looks', 'couple', 'wife', 'biggest', 'actress', 'ambanis', 'anushka', 'saw', 'time', 'padukone', 'big', 'everything', 'attire', 'lavish', 'deepika', 'verbier', 'glimpses', 'there', 'special', 'extravagant', 'featuring', 'parties', 'but', 'ranveer', 'fat', 'receptions', 'social', 'december', 'proves', 'from', 'piramal', 'switzerland', 'pleasure', 'industry', 'kapil', 'waiting', 'weddings', 'also', 'celebrated', 'long', 'squad', 'first', 'events', 'ginni', 'chopra', 'many', 'award', 'family', 'side', 'airport', 'new', 'shared', 'christmas', 'man', 'whatâ€™s', 'enough', 'not', 'outstanding', 'night', 'video', 'pink', 'come', 'london', 'audience', 'nick', 'two', 'beats', 'reason', 'gave', 'virat', 'married', 'rang', 'this', 'while', 'priyanka', 'the', 'style', 'wedding', 'jaggo', 'phones', 'jonas', '2018', 'salwar', 'friends']\n"
     ]
    }
   ],
   "source": [
    "words=list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.19208707e-03  -4.57057467e-04   5.65540045e-04   5.10682177e-04\n",
      "  -1.33018405e-03  -6.26506808e-04   5.48020413e-04  -1.38523779e-03\n",
      "  -1.32115511e-03   7.94710824e-04   1.35266501e-03   1.96988520e-04\n",
      "   1.73914348e-04   1.22015446e-03   2.50179583e-04   7.21760967e-04\n",
      "   1.13505905e-03  -1.01390167e-03   9.77296964e-04  -4.13630303e-04\n",
      "  -1.19735755e-03  -1.22274400e-03  -1.36089500e-03  -1.14474073e-03\n",
      "   9.45234264e-04   1.50892453e-03  -5.93634904e-04   1.27291062e-03\n",
      "   1.00172311e-03  -1.66610291e-03  -7.99938454e-04   9.94241913e-04\n",
      "   1.40463386e-03   1.11631374e-03  -1.00570184e-03  -1.46877384e-04\n",
      "  -1.94483830e-04   2.63748254e-04   9.85280843e-04  -1.35255733e-03\n",
      "   5.02862793e-04   1.47668412e-03  -6.45603985e-04  -1.22383994e-03\n",
      "   1.62548013e-03  -1.77793991e-04  -5.02889976e-04   5.86938346e-04\n",
      "  -4.21069330e-04  -8.95149773e-04  -3.67473316e-04   4.21759440e-04\n",
      "   1.10720597e-04  -5.16295113e-05   1.09494978e-03  -1.06434175e-03\n",
      "   2.07629364e-05  -1.49300671e-03   1.15745293e-03   1.88667051e-04\n",
      "   1.33668014e-03   1.19842603e-04   2.92918616e-04  -1.60365261e-03\n",
      "  -1.31979561e-03   1.16286799e-03   1.11721247e-03  -1.16639386e-03\n",
      "   1.62726516e-04  -3.61124345e-04   1.38699870e-05  -1.45401899e-03\n",
      "  -1.29323592e-03  -7.16147362e-04   2.72834470e-04  -1.22972613e-03\n",
      "  -1.39401306e-03  -9.89410561e-04   1.08188752e-03  -2.42231894e-04\n",
      "  -2.26536315e-04  -5.99191117e-04   1.69891980e-04  -8.55652033e-04\n",
      "  -6.88400352e-04  -1.15578901e-03   7.00828154e-04  -1.19562948e-03\n",
      "  -2.11430845e-04   3.47818714e-05  -4.75938432e-04  -4.58251248e-04\n",
      "  -1.21494127e-03  -2.58597021e-04  -1.48544190e-04  -1.49714772e-03\n",
      "   1.50980195e-03  -6.06146874e-04   1.41298003e-03  -2.47956486e-04\n",
      "  -4.14876326e-04  -4.54409746e-04   1.52225979e-03  -1.40873995e-03\n",
      "   4.75237874e-04   9.02128886e-05   1.92446736e-04  -1.11135363e-03\n",
      "  -1.24537630e-03  -1.56823406e-03  -6.76088035e-04  -9.75405565e-04\n",
      "   2.44703522e-04  -3.44787695e-04  -4.68714483e-04  -6.79487770e-04\n",
      "   4.11868859e-05  -1.59724802e-03   5.69539843e-04  -3.48211557e-04\n",
      "   1.23339682e-03   9.86210769e-04   1.41046802e-03  -7.20059790e-04\n",
      "  -7.67047168e-04   6.05975220e-04  -9.43147228e-04  -7.63789343e-04\n",
      "  -4.49987623e-04  -1.30570296e-03  -2.34374427e-04   6.60416263e-04\n",
      "  -1.97312518e-04  -6.86580825e-05   1.34195725e-03   6.36137789e-04\n",
      "  -1.29884109e-03  -6.15399738e-04  -8.94448138e-04   1.06726156e-03\n",
      "  -2.05910492e-05   8.16865009e-04  -1.09875377e-03  -7.89203972e-04\n",
      "  -6.34276075e-04   4.87571320e-04   1.35993841e-03   4.28010710e-04\n",
      "   4.10813693e-04   6.12308795e-04  -1.48217985e-03   1.06693909e-03\n",
      "  -4.51662345e-04  -1.17124710e-03  -1.29670231e-03  -4.38140647e-04\n",
      "   4.44564910e-04   1.47029513e-03  -4.01475758e-04   8.97121558e-04\n",
      "   4.20346449e-04  -1.65253223e-04   7.85553129e-04   1.22588687e-03\n",
      "  -1.19458383e-03  -8.03809729e-04   1.41826528e-03  -6.18376507e-05\n",
      "   2.22303017e-04  -1.47924328e-03  -8.37834959e-04   4.86387318e-04\n",
      "  -3.59470549e-04  -1.24764556e-04   1.57235377e-03  -5.11691440e-04\n",
      "  -1.35509868e-03  -1.32806727e-03   1.07848761e-03  -1.22893834e-03\n",
      "  -4.73702588e-04   6.92748057e-04   1.47514930e-03  -1.03550745e-04\n",
      "   1.34107552e-03  -1.45525159e-03   9.65529878e-04  -7.89868820e-04\n",
      "  -6.23424246e-04  -1.38841185e-03   1.41676713e-03   1.07693195e-03\n",
      "  -1.37221289e-03   1.21054787e-03   6.26996509e-04   2.77568197e-05\n",
      "  -1.52535294e-03   1.27866562e-03   3.67444794e-04   7.85443350e-04\n",
      "   1.60453573e-03  -8.70096672e-04  -3.35189310e-04  -7.05971906e-04\n",
      "  -1.54175155e-03  -1.27255160e-03   4.91664221e-04   3.47948488e-04\n",
      "  -1.50730298e-03   2.35370062e-05  -1.02144128e-04   1.65695115e-03\n",
      "   4.53612243e-04   3.08355520e-04  -3.70713591e-04   1.57510804e-03\n",
      "   9.83991311e-04   6.16285324e-05   1.49840838e-03   2.74678168e-04\n",
      "  -1.24486815e-03   9.42532846e-04   9.04062836e-06   6.91868248e-04\n",
      "   1.42306287e-03   7.82045609e-05  -3.10001982e-04   8.30364763e-04\n",
      "  -2.80495715e-06  -8.48621712e-04  -1.29380659e-03  -5.28795363e-06\n",
      "   8.81683256e-04  -1.03450424e-04  -5.46896481e-04  -9.78232594e-04\n",
      "   1.76660324e-04  -3.94589821e-04  -5.24540956e-04   2.37530796e-04\n",
      "   1.00317458e-03  -1.04102318e-03  -1.43523805e-03   1.10341306e-03\n",
      "   3.36184254e-04  -1.31143694e-04   1.60721154e-03   7.14821334e-04\n",
      "   1.14588242e-03   1.50972500e-03  -1.27068569e-03  -1.45065296e-03\n",
      "  -3.04417743e-04   1.09569775e-03   5.03522053e-04  -5.27817872e-04\n",
      "  -1.30519341e-03  -9.10625909e-04   7.03473808e-04   1.35773979e-03\n",
      "  -6.93834561e-04   7.10601511e-04   1.56269420e-03  -6.96648611e-04\n",
      "  -8.65078822e-04   9.73082962e-04   5.18651505e-04   1.64908147e-03\n",
      "   1.59090618e-03   4.89884289e-04  -4.09550179e-04   1.35966297e-03\n",
      "   1.59454648e-03   9.27420624e-04   7.50150473e-04   2.39535104e-04\n",
      "   1.86881894e-04  -1.22042606e-03  -1.66065642e-03  -1.52481603e-03\n",
      "  -5.24051065e-05  -1.51044584e-03   9.95907467e-04  -6.84760918e-04\n",
      "  -1.06721360e-03  -3.17447819e-04   1.11810060e-03   1.07000140e-03\n",
      "   1.62178858e-05   3.44526197e-04   9.33190691e-04  -1.30213948e-03\n",
      "  -2.38526249e-04  -5.79210755e-04   1.11390674e-03   1.03852525e-03\n",
      "   6.48494752e-04   1.05399208e-03   1.50425837e-03  -1.36854313e-03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "print(model[\"deepika\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "print(model[\"deepika\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actors = [\"ranveer\",\"deepika\",\"padukone\",\"singh\",\"nick\",\"jonas\",\"chopra\",\"priyanka\",\"virat\",\"anushka\",\"ginni\"]\n",
    "\n",
    "def predict_actor(a,b,c,word_vectors):\n",
    "    a,b,c = a.lower(),b.lower(),c.lower()\n",
    "    max_similarity = -100 \n",
    "    \n",
    "    d = None\n",
    "    words = actors\n",
    "    \n",
    "    wa,wb,wc = word_vectors[a],word_vectors[b],word_vectors[c]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for w in words:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        \n",
    "        wv = word_vectors[w]\n",
    "        sim = cosine_similarity([wb-wa],[wv-wc])\n",
    "        \n",
    "        if sim > max_similarity:\n",
    "            max_similarity = sim\n",
    "            d = w\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors=model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anushka'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = (\"nick\",\"priyanka\",\"virat\")\n",
    "predict_actor(*triad,model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ginni'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = (\"ranveer\",\"deepika\",\"priyanka\")\n",
    "predict_actor(*triad,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chopra'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = (\"ranveer\",\"singh\",\"deepika\")\n",
    "predict_actor(*triad,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virat'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = (\"deepika\",\"padukone\",\"priyanka\")\n",
    "predict_actor(*triad,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chopra'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = (\"priyanka\",\"jonas\",\"nick\")\n",
    "predict_actor(*triad,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format(\"bollywood.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Odd One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def odd_one_out(words,word_vectors):\n",
    "    \"\"\"Accepts a list of words and returns the odd word\"\"\"\n",
    "    \n",
    "    # Generate all word embeddings for the given list\n",
    "    all_word_vectors = [word_vectors[w] for w in words]\n",
    "    avg_vector = np.mean(all_word_vectors,axis=0)\n",
    "    \n",
    "    #Iterate over every word and find similarity\n",
    "    odd_one_out = None\n",
    "    min_similarity = 1.0 #Very high value\n",
    "    \n",
    "    for w in words:\n",
    "        sim = cosine_similarity([word_vectors[w]],[avg_vector])\n",
    "        if sim < min_similarity:\n",
    "            min_similarity = sim\n",
    "            odd_one_out = w\n",
    "    \n",
    "        print(\"Similairy between %s and averag vector is %.2f\"%(w,sim))\n",
    "            \n",
    "    return odd_one_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words =[\"ranveer\",\"deepika\",\"anushka\",\"style\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similairy between ranveer and averag vector is 0.51\n",
      "Similairy between deepika and averag vector is 0.55\n",
      "Similairy between anushka and averag vector is 0.54\n",
      "Similairy between style and averag vector is 0.46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'style'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_one_out(words,word_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
